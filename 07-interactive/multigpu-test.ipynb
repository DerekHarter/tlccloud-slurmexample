{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46726731-dbe0-4f38-bc5c-fd4081cb8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems necessary to have this environment variable set before tensorflow is imported, or else it doesn't take effect\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc79812-5ea2-4896-bde6-844baf66bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'TF_GPU_ALLOCATOR=cuda_malloc_async'\n",
    "#import os\n",
    "\n",
    "# this seem necessary, or else we get memory allocation errors.  Like we do next might\n",
    "# be better to set this directly through tf instead of indirectly as environment variable\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "# We get a lot of info/warning messages that make it hard to see results here.  This seems\n",
    "# pretty normal with current tensorflow, so reduce the info/warning noise\n",
    "# levels are 0=INFO, 1=WARNING, 2=ERROR, NONE\n",
    "# NOTE: the tf.get_logger() direct call doesn't seem to be working for some reason, environment\n",
    "# variable works\n",
    "#tf.get_logger().setLevel(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa636a3-561a-4c41-8cbd-4c7f6fef3312",
   "metadata": {},
   "source": [
    "# Check GPU Status / Availability\n",
    "\n",
    "On linux systems you can and should use the `nvidia-smi` tool to check that the gpu is visible, is active and has drivers installed.  You can run the command from a terminal like the following cell.\n",
    "\n",
    "I also find the following commands useful to monitor the gpu performance from the command line\n",
    "\n",
    "```\n",
    "# use watch so basic nvidia-smi redraws at top of screen each second\n",
    "$ watch -n 1 nvidia-smi\n",
    "\n",
    "# nvtop is basiclly like top for nvidia gpu\n",
    "$ sudo apt install nvtop\n",
    "$ nvtop\n",
    "\n",
    "# nvitop is similar, gives about same information, but some may prefer this one\n",
    "$ sudo apt install nvitop\n",
    "$ nvitop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f957b80-470b-4d8b-b7da-a47ad5f97694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  1 16:38:44 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:00:08.0 Off |                  N/A |\n",
      "| 25%   25C    P8              8W /  250W |       2MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:00:09.0 Off |                  N/A |\n",
      "| 27%   26C    P8              9W /  250W |       2MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:00:0A.0 Off |                  N/A |\n",
      "| 24%   24C    P8              9W /  250W |       2MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:00:0B.0 Off |                  N/A |\n",
      "| 25%   23C    P8              8W /  250W |       2MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA GeForce GTX 1080 Ti     Off |   00000000:00:0C.0 Off |                  N/A |\n",
      "| 26%   23C    P8              9W /  250W |       2MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218b71e-5a4f-4e39-9704-26527cd70732",
   "metadata": {},
   "source": [
    "# GPU to TF/Keras Availability\n",
    "\n",
    "We can check that tensorflow recognizes the presence of a GPU device as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45f010d-8eb5-4517-8a16-af817c0b2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Devices :  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU')]\n",
      "Num GPUs Available:  5\n"
     ]
    }
   ],
   "source": [
    "print('Available Devices : ', tf.config.list_physical_devices())\n",
    "print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b01199-1cc7-42bd-bc00-a38a984f8d1f",
   "metadata": {},
   "source": [
    "# Common Setup to Test Multi-GPU Strategy\n",
    "\n",
    "These functions create a compiled model we will fit data to using 1 and multiple cpus\n",
    "under a Mirrored Strategy.  We load and reuse the same data and same model parameter for\n",
    "both model fit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9495e41-c83d-46c2-b5c9-cc7a0c70b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    # Make a simple 2-layer densely-connected neural network.\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4096, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    batch_size = 1024\n",
    "    num_val_samples = 10000\n",
    "\n",
    "    # Return the MNIST dataset in the form of a `tf.data.Dataset`.\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Preprocess the data (these are Numpy arrays)\n",
    "    x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    y_train = y_train.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    # Reserve num_val_samples samples for validation\n",
    "    x_val = x_train[-num_val_samples:]\n",
    "    y_val = y_train[-num_val_samples:]\n",
    "    x_train = x_train[:-num_val_samples]\n",
    "    y_train = y_train[:-num_val_samples]\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37cf130-8662-4048-8817-2d943f68cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on all available devices.\n",
    "train_dataset, val_dataset, test_dataset = get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59411b41-4afe-494f-ac97-f5fdf0a24648",
   "metadata": {},
   "source": [
    "# Performance on Single GPU\n",
    "\n",
    "We can specify which devices to mirror in the strategy when it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235ea1f3-b817-4cf9-9609-b136348d65bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "49/49 [==============================] - 22s 419ms/step - loss: 2.4925 - sparse_categorical_accuracy: 0.1124 - val_loss: 2.3003 - val_sparse_categorical_accuracy: 0.1599\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 16s 328ms/step - loss: 2.3012 - sparse_categorical_accuracy: 0.1194 - val_loss: 2.3021 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 16s 327ms/step - loss: 2.3010 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3021 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.7055 - sparse_categorical_accuracy: 0.1144 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.3010 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 16s 332ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 16s 331ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 16s 331ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 16s 332ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 16s 332ms/step - loss: 2.3077 - sparse_categorical_accuracy: 0.1121 - val_loss: 2.3018 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 16s 332ms/step - loss: 2.3012 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3019 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3019 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 16s 329ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3021 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 16s 328ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 16s 328ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 16s 329ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 16s 328ms/step - loss: 2.3125 - sparse_categorical_accuracy: 0.1125 - val_loss: 2.3053 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 16s 328ms/step - loss: 15.9147 - sparse_categorical_accuracy: 0.1044 - val_loss: 2.3740 - val_sparse_categorical_accuracy: 0.0946\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 16s 329ms/step - loss: 4.4498 - sparse_categorical_accuracy: 0.1012 - val_loss: 4.3713 - val_sparse_categorical_accuracy: 0.0837\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 3.3250 - sparse_categorical_accuracy: 0.0992 - val_loss: 2.3459 - val_sparse_categorical_accuracy: 0.0983\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.4871 - sparse_categorical_accuracy: 0.1046 - val_loss: 2.3018 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 16s 331ms/step - loss: 3.3674 - sparse_categorical_accuracy: 0.1078 - val_loss: 2.3027 - val_sparse_categorical_accuracy: 0.1090\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.9470 - sparse_categorical_accuracy: 0.1070 - val_loss: 2.3873 - val_sparse_categorical_accuracy: 0.0990\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.5218 - sparse_categorical_accuracy: 0.1125 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.1465\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.3108 - sparse_categorical_accuracy: 0.1367 - val_loss: 15.7052 - val_sparse_categorical_accuracy: 0.0992\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 16s 331ms/step - loss: 2.6581 - sparse_categorical_accuracy: 0.1149 - val_loss: 2.3076 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.2221 - sparse_categorical_accuracy: 0.1494 - val_loss: 2.2216 - val_sparse_categorical_accuracy: 0.1721\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.3260 - sparse_categorical_accuracy: 0.1100 - val_loss: 2.3003 - val_sparse_categorical_accuracy: 0.1094\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 16s 330ms/step - loss: 2.3394 - sparse_categorical_accuracy: 0.1262 - val_loss: 2.3026 - val_sparse_categorical_accuracy: 0.1064\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 16s 331ms/step - loss: 2.2998 - sparse_categorical_accuracy: 0.1132 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.1064\n",
      "1min 22s ± 241 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n",
      "1.19 s ± 7.5 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy(['GPU:0'])\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model = get_compiled_model()\n",
    "\n",
    "%timeit -r 5 model.fit(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "\n",
    "# Test the model on all available devices.\n",
    "%timeit -r 10 model.evaluate(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3548f8-4513-4bc0-91d3-fb5e0eab10eb",
   "metadata": {},
   "source": [
    "# Performance on Multiple GPUs\n",
    "\n",
    "If you don't specify specific gpu resources to use in the mirrored strategy, then all discovered /\n",
    "available gpus will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50747e9-8ad0-4b93-89a1-c8eaa1231a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n",
      "Number of devices: 5\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:Error reported to Coordinator: OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 323, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 667, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 396, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 478, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 788, in run_step\n",
      "    outputs = model.train_step(data)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 757, in train_step\n",
      "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 498, in minimize\n",
      "    return self.apply_gradients(grads_and_vars, name=name)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 604, in apply_gradients\n",
      "    self._create_all_weights(var_list)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 783, in _create_all_weights\n",
      "    self._create_slots(var_list)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/adam.py\", line 127, in _create_slots\n",
      "    self.add_slot(var, 'm')\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 847, in add_slot\n",
      "    weight = tf_variables.Variable(\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\n",
      "    return cls._variable_v2_call(*args, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 244, in _variable_v2_call\n",
      "    return previous_getter(\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 67, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2186, in create_colocated_variable\n",
      "    return next_creator(**kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 67, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/shared_variable_creator.py\", line 69, in create_new_variable\n",
      "    v = next_creator(**kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 67, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2083, in creator_with_resource_vars\n",
      "    created = self._create_variable(next_creator, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 486, in _create_variable\n",
      "    return distribute_utils.create_mirrored_variable(\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_utils.py\", line 311, in create_mirrored_variable\n",
      "    value_list = real_mirrored_creator(**kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 481, in _real_mirrored_creator\n",
      "    v = next_creator(**kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 67, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 712, in variable_capturing_scope\n",
      "    v = UnliftedInitializerVariable(\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\n",
      "    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 227, in __init__\n",
      "    initial_value = initial_value()\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\", line 139, in __call__\n",
      "    return super(Zeros, self).__call__(shape, dtype=_get_dtype(dtype), **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py\", line 154, in __call__\n",
      "    return array_ops.zeros(shape, dtype)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2819, in wrapped\n",
      "    tensor = fun(*args, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2880, in zeros\n",
      "    output = fill(shape, constant(zero, dtype=dtype), name=name)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 239, in fill\n",
      "    result = gen_array_ops.fill(dims, value, name=name)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3348, in fill\n",
      "    _ops.raise_from_not_ok_status(e, name)\n",
      "  File \"/home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 6862, in raise_from_not_ok_status\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:628 _call_for_each_replica\n        return mirrored_run.call_for_each_replica(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:93 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:234 _call_for_each_replica\n        coord.join(threads)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/six.py:719 reraise\n        raise value\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:323 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:604 apply_gradients\n        self._create_all_weights(var_list)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:783 _create_all_weights\n        self._create_slots(var_list)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/adam.py:127 _create_slots\n        self.add_slot(var, 'm')\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:847 add_slot\n        weight = tf_variables.Variable(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:262 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:244 _variable_v2_call\n        return previous_getter(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2186 create_colocated_variable\n        return next_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/shared_variable_creator.py:69 create_new_variable\n        v = next_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2083 creator_with_resource_vars\n        created = self._create_variable(next_creator, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:486 _create_variable\n        return distribute_utils.create_mirrored_variable(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_utils.py:311 create_mirrored_variable\n        value_list = real_mirrored_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:481 _real_mirrored_creator\n        v = next_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:712 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:227 __init__\n        initial_value = initial_value()\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py:139 __call__\n        return super(Zeros, self).__call__(shape, dtype=_get_dtype(dtype), **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:154 __call__\n        return array_ops.zeros(shape, dtype)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2819 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2880 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:239 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:3348 fill\n        _ops.raise_from_not_ok_status(e, name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6862 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Everything that creates variables should be under the strategy scope.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# In general this is only model construction & `compile()`.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m get_compiled_model()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-r 5 model.fit(train_dataset, epochs=5, validation_data=val_dataset)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Test the model on all available devices.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-r 10 model.evaluate(test_dataset)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/IPython/core/magics/execution.py:1185\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1184\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1185\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: in user code:\n\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:628 _call_for_each_replica\n        return mirrored_run.call_for_each_replica(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:93 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:234 _call_for_each_replica\n        coord.join(threads)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/six.py:719 reraise\n        raise value\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py:323 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:604 apply_gradients\n        self._create_all_weights(var_list)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:783 _create_all_weights\n        self._create_slots(var_list)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/adam.py:127 _create_slots\n        self.add_slot(var, 'm')\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:847 add_slot\n        weight = tf_variables.Variable(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:262 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:244 _variable_v2_call\n        return previous_getter(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2186 create_colocated_variable\n        return next_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/shared_variable_creator.py:69 create_new_variable\n        v = next_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2083 creator_with_resource_vars\n        created = self._create_variable(next_creator, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:486 _create_variable\n        return distribute_utils.create_mirrored_variable(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_utils.py:311 create_mirrored_variable\n        value_list = real_mirrored_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:481 _real_mirrored_creator\n        v = next_creator(**kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:712 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:227 __init__\n        initial_value = initial_value()\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py:139 __call__\n        return super(Zeros, self).__call__(shape, dtype=_get_dtype(dtype), **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:154 __call__\n        return array_ops.zeros(shape, dtype)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2819 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2880 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:239 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:3348 fill\n        _ops.raise_from_not_ok_status(e, name)\n    /home/dash/.conda/envs/keras-tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6862 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model = get_compiled_model()\n",
    "\n",
    "%timeit -r 5 model.fit(train_dataset, epochs=5, validation_data=val_dataset)\n",
    "\n",
    "# Test the model on all available devices.\n",
    "%timeit -r 10 model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d327ac-338f-47ed-ba9d-588b82f6732b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
